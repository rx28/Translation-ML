{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Seq2SeqImplementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPL0hIlGKoA"
      },
      "source": [
        "# <font color='red'>**Sequence to sequence implementation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvNSZXNkkOkO"
      },
      "source": [
        "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
        "\n",
        "2. You will find **ita.txt** file in that ZIP, \n",
        "you can read that data using python and preprocess that data this way only: \n",
        "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
        "    \n",
        "3. Implement a simple Encoder and Decoder architecture  \n",
        "\n",
        "4.  BLEU score as metric to evaluate your model.\n",
        "\n",
        "5. Use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k_AlAuKJqVA"
      },
      "source": [
        "<font color='blue'>**Load the data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU80Ao-AGaob",
        "outputId": "e5e2a400-b4e3-48fe-814f-be1d1079cb46"
      },
      "source": [
        "!wget http://www.manythings.org/anki/ita-eng.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-07 08:45:02--  http://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.186.54, 104.21.92.44, 2606:4700:3030::6815:5c2c, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.186.54|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7730753 (7.4M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "ita-eng.zip         100%[===================>]   7.37M  2.75MB/s    in 2.7s    \n",
            "\n",
            "2021-08-07 08:45:04 (2.75 MB/s) - ‘ita-eng.zip’ saved [7730753/7730753]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCj1KriwtYFs",
        "outputId": "ba039533-1004-44db-9bd4-f9b089042571"
      },
      "source": [
        "!unzip ita-eng.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmGWTdRmKRph"
      },
      "source": [
        "<font color='blue'>**Preprocess data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QqElB_nKZos",
        "outputId": "4592ffaa-f377-46ea-fb07-e779b328d9c4"
      },
      "source": [
        "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-07 08:45:05--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
            "--2021-08-07 08:45:06--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca20d8662a6aefd3403154d580c.dl.dropboxusercontent.com/cd/0/inline/BTw3dHbPe3-8x37JovizGjpBsywSfkOXmVson6eDhr8CT0F0l6NQ7Ra7w0yOxey30G8yAAI5BU_fsAHUfUGgcENVOIfCjCbEjpZrOO_tFySXuvCT6HpQlFQ7RJd1Jp0EpRgd7epXY7Nrd5XRi1-Nn4-W/file# [following]\n",
            "--2021-08-07 08:45:07--  https://uca20d8662a6aefd3403154d580c.dl.dropboxusercontent.com/cd/0/inline/BTw3dHbPe3-8x37JovizGjpBsywSfkOXmVson6eDhr8CT0F0l6NQ7Ra7w0yOxey30G8yAAI5BU_fsAHUfUGgcENVOIfCjCbEjpZrOO_tFySXuvCT6HpQlFQ7RJd1Jp0EpRgd7epXY7Nrd5XRi1-Nn4-W/file\n",
            "Resolving uca20d8662a6aefd3403154d580c.dl.dropboxusercontent.com (uca20d8662a6aefd3403154d580c.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uca20d8662a6aefd3403154d580c.dl.dropboxusercontent.com (uca20d8662a6aefd3403154d580c.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘glove.6B.100d.txt’\n",
            "\n",
            "glove.6B.100d.txt   100%[===================>] 331.04M   113MB/s    in 2.9s    \n",
            "\n",
            "2021-08-07 08:45:10 (113 MB/s) - ‘glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXdcVHle9XpA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,TensorBoard,ReduceLROnPlateau,EarlyStopping\n",
        "import nltk.translate.bleu_score as bleu\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from nltk.translate import bleu_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "YvfwFa7c9iQq",
        "outputId": "73162641-2202-49ea-ca40-d34b659ddc20"
      },
      "source": [
        "with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "    eng=[]\n",
        "    ita=[]\n",
        "    for i in f.readlines():\n",
        "        eng.append(i.split(\"\\t\")[0])\n",
        "        ita.append(i.split(\"\\t\")[1])\n",
        "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(352040, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english   italian\n",
              "0     Hi.     Ciao!\n",
              "1     Hi.     Ciao.\n",
              "2    Run!    Corri!\n",
              "3    Run!    Corra!\n",
              "4    Run!  Correte!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sH4Tfl3g9lRB",
        "outputId": "0f1095c4-6177-4555-c874-356ddc4b6f68"
      },
      "source": [
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "    # remove all the spacial characters: except space ' '\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_ita(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # I have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data \n",
        "    \n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "data['english'] = data['english'].apply(preprocess)\n",
        "data['italian'] = data['italian'].apply(preprocess_ita)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1      hi     ciao\n",
              "2     run    corri\n",
              "3     run    corra\n",
              "4     run  correte"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ESNcDx9f914L",
        "outputId": "6cab38e4-4307-45ac-b41a-7e1d237ca61b"
      },
      "source": [
        "data['italian_len'] = data['italian'].str.split().apply(len)\n",
        "data = data[data['italian_len'] < 20]\n",
        "\n",
        "data['english_len'] = data['english'].str.split().apply(len)\n",
        "data = data[data['english_len'] < 20]\n",
        "\n",
        "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
        "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
        "\n",
        "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
        "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>corri</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>corra</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>correte</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   italian  english_inp english_out\n",
              "0     ciao   <start> hi    hi <end>\n",
              "1     ciao   <start> hi    hi <end>\n",
              "2    corri  <start> run   run <end>\n",
              "3    corra  <start> run   run <end>\n",
              "4  correte  <start> run   run <end>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "yxouecbE93RR",
        "outputId": "f636e03c-06f1-4550-d6b2-ced2a0eee895"
      },
      "source": [
        "data.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>142693</th>\n",
              "      <td>tom dice di aver baciato mary</td>\n",
              "      <td>&lt;start&gt; tom says he kissed mary</td>\n",
              "      <td>tom says he kissed mary &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109273</th>\n",
              "      <td>loro erano degli sfidanti</td>\n",
              "      <td>&lt;start&gt; there were challenges</td>\n",
              "      <td>there were challenges &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345384</th>\n",
              "      <td>ti dispiace chiudere la porta per niente</td>\n",
              "      <td>&lt;start&gt; would you mind shutting the door no no...</td>\n",
              "      <td>would you mind shutting the door no not at all...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221138</th>\n",
              "      <td>tom suona bene larmonica</td>\n",
              "      <td>&lt;start&gt; tom plays the harmonica well</td>\n",
              "      <td>tom plays the harmonica well &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213460</th>\n",
              "      <td>non sapevo che vi piacesse mary</td>\n",
              "      <td>&lt;start&gt; i did not know you liked mary</td>\n",
              "      <td>i did not know you liked mary &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216589</th>\n",
              "      <td>io non sono ancora felice a riguardo</td>\n",
              "      <td>&lt;start&gt; i am still not happy about it</td>\n",
              "      <td>i am still not happy about it &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192159</th>\n",
              "      <td>cosa vuole sapere tom</td>\n",
              "      <td>&lt;start&gt; what does tom want to know</td>\n",
              "      <td>what does tom want to know &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239741</th>\n",
              "      <td>ha la patente</td>\n",
              "      <td>&lt;start&gt; do you have a driver is license</td>\n",
              "      <td>do you have a driver is license &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86896</th>\n",
              "      <td>datemi unaltra birra</td>\n",
              "      <td>&lt;start&gt; give me another beer</td>\n",
              "      <td>give me another beer &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36919</th>\n",
              "      <td>preparai degli spaghetti</td>\n",
              "      <td>&lt;start&gt; i made spaghetti</td>\n",
              "      <td>i made spaghetti &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         italian  ...                                        english_out\n",
              "142693             tom dice di aver baciato mary  ...                      tom says he kissed mary <end>\n",
              "109273                 loro erano degli sfidanti  ...                        there were challenges <end>\n",
              "345384  ti dispiace chiudere la porta per niente  ...  would you mind shutting the door no not at all...\n",
              "221138                  tom suona bene larmonica  ...                 tom plays the harmonica well <end>\n",
              "213460           non sapevo che vi piacesse mary  ...                i did not know you liked mary <end>\n",
              "216589      io non sono ancora felice a riguardo  ...                i am still not happy about it <end>\n",
              "192159                     cosa vuole sapere tom  ...                   what does tom want to know <end>\n",
              "239741                             ha la patente  ...              do you have a driver is license <end>\n",
              "86896                       datemi unaltra birra  ...                         give me another beer <end>\n",
              "36919                   preparai degli spaghetti  ...                             i made spaghetti <end>\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJSPYiCpx_XN"
      },
      "source": [
        "data.to_csv('preprocessed_seq',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A05hhCLwyMrv"
      },
      "source": [
        "data2=pd.read_csv('preprocessed_seq')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za1AkanJ-uKa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(data2, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZenBqVPyiuj",
        "outputId": "7f125b1b-5209-4791-80c3-8b8b51415fbe"
      },
      "source": [
        "print(train.shape, validation.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(281244, 3) (70311, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlpK1NkZ-vHb"
      },
      "source": [
        "\n",
        "# for one sentence I will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this I can use only one tokenizer for both encoder output and decoder output\n",
        "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
        "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "u0HvbffU-wxl",
        "outputId": "8f2a55e5-fa0e-49b8-bc26-f206bd095ba7"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>210209</th>\n",
              "      <td>molte persone lo fanno qui</td>\n",
              "      <td>&lt;start&gt; a lot of people do that here &lt;end&gt;</td>\n",
              "      <td>a lot of people do that here &lt;end&gt; &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202859</th>\n",
              "      <td>lei ha un enorme appetito</td>\n",
              "      <td>&lt;start&gt; she has a gigantic appetite</td>\n",
              "      <td>she has a gigantic appetite &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37409</th>\n",
              "      <td>io voglio mangiarlo</td>\n",
              "      <td>&lt;start&gt; i want to eat it</td>\n",
              "      <td>i want to eat it &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43088</th>\n",
              "      <td>che cosha detto</td>\n",
              "      <td>&lt;start&gt; what did she say</td>\n",
              "      <td>what did she say &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198402</th>\n",
              "      <td>non voglio che tom si arrenda</td>\n",
              "      <td>&lt;start&gt; i do not want tom to give up</td>\n",
              "      <td>i do not want tom to give up &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              italian  ...                               english_out\n",
              "210209     molte persone lo fanno qui  ...  a lot of people do that here <end> <end>\n",
              "202859      lei ha un enorme appetito  ...         she has a gigantic appetite <end>\n",
              "37409             io voglio mangiarlo  ...                    i want to eat it <end>\n",
              "43088                 che cosha detto  ...                    what did she say <end>\n",
              "198402  non voglio che tom si arrenda  ...        i do not want tom to give up <end>\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "sjAkOfFf-y85",
        "outputId": "0fc8aacf-bb69-4193-deef-69748f8d6701"
      },
      "source": [
        "ita_lengths = train['italian'].str.split().apply(len)\n",
        "eng_lengths = train['english_inp'].str.split().apply(len)\n",
        "import seaborn as sns\n",
        "sns.kdeplot(ita_lengths)\n",
        "plt.show()\n",
        "sns.kdeplot(eng_lengths)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "## <font color='blue'>**Implement custom encoder decoder**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A45uc0JILMlV"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T7ehBs--p_T"
      },
      "source": [
        "tknizer_ita = Tokenizer()\n",
        "tknizer_ita.fit_on_texts(train['italian'].values)\n",
        "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_eng.fit_on_texts(train['english_inp'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vac5X91s-sJr",
        "outputId": "12ce3cac-255c-4307-922d-2bde1513674b"
      },
      "source": [
        "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
        "print(vocab_size_eng)\n",
        "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
        "print(vocab_size_ita)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13077\n",
            "26577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_cpMsdh-4a2",
        "outputId": "de04b974-6f5b-44c1-ce18-d4481d17f93a"
      },
      "source": [
        "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10277)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Oe0mPE-Lrk"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\n",
        "for word, i in tknizer_eng.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-sB5uEE-IMV"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, enc_vocab_size, embedding_dim, enc_lstm_size, input_length):\n",
        "        super().__init__()\n",
        "        self.enc_vocab_size = enc_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.encoder_output=0\n",
        "        self.lstm_size=enc_lstm_size\n",
        "        self.lstm_output = 0\n",
        "        self.enc_state_h=0\n",
        "        self.enc_state_c=0\n",
        "      \n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.embedding = Embedding(input_dim=self.enc_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "        \n",
        "    def call(self, input_sentances, training=True):\n",
        "        input_embedd= self.embedding(input_sentances)\n",
        "        self.encoder_output, self.enc_state_h,self.enc_state_c = self.lstm(input_embedd)\n",
        "        return self.encoder_output, self.enc_state_h,self.enc_state_c\n",
        "\n",
        "    def initialize_states(self, batch_size):\n",
        "\n",
        "        lstm_h=tf.zeros(shape=[batch_size,self.lstm_size])\n",
        "        lstm_c=tf.zeros(shape=[batch_size,self.lstm_size])\n",
        "\n",
        "        return [lstm_h,lstm_c]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtbOI3VwLOe0"
      },
      "source": [
        "<font color='orange'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziSqOgmhLOe1",
        "outputId": "37013ad7-1cc2-427e-b6ba-8fea6b71c0a7"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    #Intialzing encoder \n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    #Intializing encoder initial states\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    \n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6fNro7E_5sD"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, dec_vocab_size, embedding_dim, dec_lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.vocab_size = dec_vocab_size\n",
        "        self.embedding_dim = 100\n",
        "        #self.dec_units = dec_units\n",
        "        self.lstm_size=dec_lstm_size\n",
        "        self.input_length = input_length\n",
        "        # we are using embedding_matrix and not training the embedding layer\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_decoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_sequences=True, return_state=True, name=\"Decoder_LSTM\")\n",
        "    \n",
        "    def call(self, target_sentances, initial_state):\n",
        "        target_embedd = self.embedding(target_sentances)\n",
        "        decoder_output,lstm_h,lstm_c = self.lstm(target_embedd, initial_state)\n",
        "        return decoder_output,lstm_h,lstm_c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kWhwgLNA_NW"
      },
      "source": [
        "# intial_hidden_state=np.zeros((batch_size,self.lstm_size))\n",
        "# intial_cell_state=np.zeros((batch_size,self.lstm_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-I0SUbLOe8"
      },
      "source": [
        "<font color='orange'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B0gokgKLOe8",
        "outputId": "d607c0b7-cfc2-458e-c072-18dac41b9ae3"
      },
      "source": [
        "def grader_decoder():\n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    states=[state_h,state_c]\n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
        "    output,_,_=decoder(target_sentences, states)\n",
        "    assert(output.shape==(batch_size,input_length,dec_units))\n",
        "    return True\n",
        "print(grader_decoder())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXrIj4scLOe_"
      },
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, enc_inputs_len,dec_inputs_len, ed_vocab_size,batch_size):\n",
        "        \n",
        "        #Create encoder object\n",
        "        #Create decoder object\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc=Encoder(enc_vocab_size=vocab_size_ita+1,embedding_dim=50,enc_lstm_size=256,input_length=enc_inputs_len)\n",
        "        self.dec=Decoder(dec_vocab_size=vocab_size_eng+1,embedding_dim=100,dec_lstm_size=256,input_length=dec_inputs_len)\n",
        "        self.dense_ed=Dense(ed_vocab_size, activation='softmax')\n",
        "        self.enc_states=self.enc.initialize_states(batch_size)\n",
        "    \n",
        "    \n",
        "    def call(self,input_ed):\n",
        "\n",
        "      data_enc=input_ed[0]\n",
        "      data_dec=input_ed[1]\n",
        "      encoder_output,final_state_h,final_state_c=self.enc(data_enc,self.enc_states)\n",
        "      decoder_output,state_h,state_c=self.dec(data_dec,[final_state_h,final_state_c])\n",
        "      dense_ed=self.dense_ed(decoder_output)\n",
        "\n",
        "      return dense_ed\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGCD58nB-eCU"
      },
      "source": [
        "class Data_en:\n",
        "    def __init__(self, data2, tknizer_ita, tknizer_eng, len_data):\n",
        "        self.in_encoder = data2['italian'].values\n",
        "        self.in_decoder = data2['english_inp'].values\n",
        "        self.out_decoder = data2['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.len_data = len_data\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.in_encoder[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.in_decoder[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.out_decoder[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.in_encoder)\n",
        "\n",
        "    \n",
        "class LoadData(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, data_lan, batch_size=1):\n",
        "        self.data_lan = data_lan\n",
        "        self.batch_size = batch_size\n",
        "        self.index_data = np.arange(len(self.data_lan.in_encoder))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        a = i * self.batch_size\n",
        "        b = (i + 1) * self.batch_size\n",
        "        data_val = []\n",
        "        for j in range(a, b):\n",
        "            data_val.append(self.data_lan[j])\n",
        "\n",
        "        batch_data = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data_val)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch_data[0],batch_data[1]],batch_data[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.index_data) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.index_data = np.random.permutation(self.index_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFlvl8On-gEk",
        "outputId": "dfe9e05c-fc0a-48b6-eb68-85db0d6f9b1f"
      },
      "source": [
        "train_enc1 = Data_en(train, tknizer_ita, tknizer_eng, 20)\n",
        "test_ecn1  = Data_en(validation, tknizer_ita, tknizer_eng, 20)\n",
        "\n",
        "train_load = LoadData(train_enc1, batch_size=1024)\n",
        "test_load = LoadData(test_ecn1, batch_size=1024)\n",
        "\n",
        "\n",
        "print(train_load[0][0][0].shape, train_load[0][0][1].shape, train_load[0][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1024, 20) (1024, 20) (1024, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOPM-5-KJVbE",
        "outputId": "671f222f-5a6f-4553-c7e9-2fca6c78adce"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "\n",
        "\n",
        "logdir1 = os.path.join(\"logs1\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback1= tf.keras.callbacks.TensorBoard(logdir1, histogram_freq=1)\n",
        "\n",
        "model1=Encoder_decoder(enc_inputs_len=20,dec_inputs_len=20,ed_vocab_size=vocab_size_eng,batch_size=1024)\n",
        "model1.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy')\n",
        "train_steps1=train.shape[0]//1024\n",
        "valid_steps1=validation.shape[0]//1024\n",
        "model1.fit(train_load, steps_per_epoch=train_steps1, epochs=35, validation_data=train_load, validation_steps=valid_steps1,callbacks=[tensorboard_callback1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "274/274 [==============================] - 88s 295ms/step - loss: 1.8474 - val_loss: 1.6069\n",
            "Epoch 2/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 1.4759 - val_loss: 1.3590\n",
            "Epoch 3/35\n",
            "274/274 [==============================] - 71s 258ms/step - loss: 1.2951 - val_loss: 1.2232\n",
            "Epoch 4/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 1.1606 - val_loss: 1.0843\n",
            "Epoch 5/35\n",
            "274/274 [==============================] - 72s 263ms/step - loss: 1.0302 - val_loss: 0.9641\n",
            "Epoch 6/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.9232 - val_loss: 0.8679\n",
            "Epoch 7/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.8336 - val_loss: 0.7833\n",
            "Epoch 8/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.7548 - val_loss: 0.7082\n",
            "Epoch 9/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.6850 - val_loss: 0.6437\n",
            "Epoch 10/35\n",
            "274/274 [==============================] - 72s 261ms/step - loss: 0.6234 - val_loss: 0.5839\n",
            "Epoch 11/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.5681 - val_loss: 0.5316\n",
            "Epoch 12/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.5192 - val_loss: 0.4848\n",
            "Epoch 13/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.4747 - val_loss: 0.4442\n",
            "Epoch 14/35\n",
            "274/274 [==============================] - 72s 262ms/step - loss: 0.4353 - val_loss: 0.4045\n",
            "Epoch 15/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.4000 - val_loss: 0.3722\n",
            "Epoch 16/35\n",
            "274/274 [==============================] - 72s 261ms/step - loss: 0.3689 - val_loss: 0.3453\n",
            "Epoch 17/35\n",
            "274/274 [==============================] - 71s 258ms/step - loss: 0.3408 - val_loss: 0.3170\n",
            "Epoch 18/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.3161 - val_loss: 0.2933\n",
            "Epoch 19/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.2938 - val_loss: 0.2752\n",
            "Epoch 20/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.2740 - val_loss: 0.2551\n",
            "Epoch 21/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.2560 - val_loss: 0.2399\n",
            "Epoch 22/35\n",
            "274/274 [==============================] - 72s 263ms/step - loss: 0.2398 - val_loss: 0.2227\n",
            "Epoch 23/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.2253 - val_loss: 0.2090\n",
            "Epoch 24/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.2118 - val_loss: 0.1983\n",
            "Epoch 25/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.2002 - val_loss: 0.1870\n",
            "Epoch 26/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.1894 - val_loss: 0.1768\n",
            "Epoch 27/35\n",
            "274/274 [==============================] - 72s 262ms/step - loss: 0.1792 - val_loss: 0.1670\n",
            "Epoch 28/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.1700 - val_loss: 0.1576\n",
            "Epoch 29/35\n",
            "274/274 [==============================] - 72s 262ms/step - loss: 0.1617 - val_loss: 0.1496\n",
            "Epoch 30/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.1538 - val_loss: 0.1436\n",
            "Epoch 31/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.1470 - val_loss: 0.1363\n",
            "Epoch 32/35\n",
            "274/274 [==============================] - 72s 262ms/step - loss: 0.1402 - val_loss: 0.1311\n",
            "Epoch 33/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.1339 - val_loss: 0.1253\n",
            "Epoch 34/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.1279 - val_loss: 0.1197\n",
            "Epoch 35/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.1225 - val_loss: 0.1144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22bb973990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnQcAMhrpDj2",
        "outputId": "eda5bd2f-503b-4264-f401-cb0e6cdd3220"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_1 (Encoder)          multiple                  1643268   \n",
            "_________________________________________________________________\n",
            "decoder_1 (Decoder)          multiple                  1673368   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  3360789   \n",
            "=================================================================\n",
            "Total params: 6,677,425\n",
            "Trainable params: 6,677,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2R2fS28sJs-"
      },
      "source": [
        "%reload_ext  tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "1yc0b7ApsNJ8",
        "outputId": "04124b14-cd13-4ffa-8c9d-98ebfee23147"
      },
      "source": [
        "%tensorboard --logdir logs1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6007, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ0Xio6wpGVL"
      },
      "source": [
        "model1.save_weights('encoder_decoder_task1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKJP9CkHthjF"
      },
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "  in_enc_ita=tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  in_pad_seq_ita=pad_sequences(in_enc_ita,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
        "  embed_pred=model1.layers[0].embedding(in_pad_seq_ita)\n",
        "  enc_ouput1,enc_state_h1,enc_state_c1=model1.layers[0].lstm(embed_pred)\n",
        "  in_indexs_2d=tknizer_eng.word_index['<start>']\n",
        "  in_indexs_2d=np.reshape(in_indexs_2d,(1,1))\n",
        "  att=np.zeros((20,20))\n",
        "  input_list=[]\n",
        "  for j in range(20):\n",
        "    out_pred,dec_state_h1,dec_state_c1=model1.layers[1](in_indexs_2d,[enc_state_h1,enc_state_c1])\n",
        "    dense_out1=model1.layers[2](out_pred)\n",
        "    enc_state_h1=dec_state_h1\n",
        "    enc_state_c1=dec_state_c1\n",
        "    out_index=np.argmax(dense_out1)\n",
        "    in_indexs_2d=np.reshape(out_index,(1,1))\n",
        "    input_list.append(tknizer_eng.index_word[out_index])\n",
        "    if tknizer_eng.index_word[out_index]=='<end>':\n",
        "      break\n",
        "  return ' '.join(input_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "996pFO8BLOfG"
      },
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP3A7cr3_OCd",
        "outputId": "9cf74cba-bff5-44e0-d893-b68b1e8a2765"
      },
      "source": [
        "ita=validation['italian'].values[:1000]\n",
        "eng=validation['english_out'].values[:1000]\n",
        "blue=[]\n",
        "for i in range(1000):\n",
        "  pred_bl=predict(ita[i])\n",
        "  blue.append(bleu_score.sentence_bleu(eng[i],pred_bl))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0xt6Oi2_WCK",
        "outputId": "f1cf4a09-085e-426d-aa3b-12df27debad3"
      },
      "source": [
        "print(f'Bleu_score: {np.average(blue)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu_score: 0.8361471092114097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxWFDxZXLOfJ"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhX3K9GLOfJ"
      },
      "source": [
        "## Task -2: Including Attention mechanisum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3d7GeBMGbsJ"
      },
      "source": [
        "1. Use the preprocessed data from Task-1\n",
        "\n",
        "2. You have to implement an Encoder and Decoder architecture with  \n",
        "attention as discussed in the reference notebook.\n",
        "\n",
        "    * Encoder   - with 1 layer LSTM <br>\n",
        "    * Decoder   - with 1 layer LSTM<br>\n",
        "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
        "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
        " As a part of this assignment **you need to create 3 models for each scoring function**\n",
        "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
        "\n",
        "    * In model 1 you need to implemnt \"dot\" score function\n",
        "    * In model 2 you need to implemnt \"general\" score function\n",
        "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
        "    \n",
        " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
        "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
        "\n",
        "5. Using attention weights, you can plot the attention plots, \n",
        "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
        "\n",
        "6. The attention layer has to be written by yourself only. \n",
        "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
        "\n",
        "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
        "\n",
        "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
        " Check the reference notebook for better understanding.\n",
        "\n",
        "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "11. Resources:\n",
        "    a. Check the reference notebook\n",
        "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
        "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
        "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4KIsGxLOfK"
      },
      "source": [
        "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdVfhBgmZoaf"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, enc_vocab_size, embedding_dim, enc_lstm_size, input_length):\n",
        "        super().__init__()\n",
        "        self.enc_vocab_size = enc_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.encoder_output=0\n",
        "        self.lstm_size=enc_lstm_size\n",
        "        self.lstm_output = 0\n",
        "        self.enc_state_h=0\n",
        "        self.enc_state_c=0\n",
        "      \n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.embedding = Embedding(input_dim=self.enc_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "        \n",
        "    def call(self, input_sentances, training=True):\n",
        "        input_embedd= self.embedding(input_sentances)\n",
        "        self.encoder_output, self.enc_state_h,self.enc_state_c = self.lstm(input_embedd)\n",
        "        return self.encoder_output, self.enc_state_h,self.enc_state_c\n",
        "\n",
        "    def initialize_states(self, batch_size):\n",
        "\n",
        "        lstm_h=tf.zeros(shape=[batch_size,self.lstm_size])\n",
        "        lstm_c=tf.zeros(shape=[batch_size,self.lstm_size])\n",
        "\n",
        "        return [lstm_h,lstm_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ub9aN-hK244"
      },
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRoe65b9LB0D",
        "outputId": "2dbf869d-ea61-4979-d83c-c7ec3eb0ea56"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    \n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units in encoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "<font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFoDGWQLxE81"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "  '''\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "    super().__init__()\n",
        "    self.scoring_function=scoring_function\n",
        "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "    if self.scoring_function=='dot':\n",
        "      # Intialize variables needed for Dot score function here\n",
        "      self.att_units=att_units\n",
        "      self.softmax1=tf.keras.layers.Softmax(axis=1)\n",
        "    if scoring_function == 'general':\n",
        "      # Intialize variables needed for General score function here\n",
        "      # Initializing the weights\n",
        "      self.dense1=tf.keras.layers.Dense(self.att_units)\n",
        "      self.softmax1=tf.keras.layers.Softmax(axis=1)\n",
        "    elif scoring_function == 'concat':\n",
        "      # Intialize variables needed for Concat score function here\n",
        "      self.dense2=tf.keras.layers.Dense(self.att_units,activation='tanh')\n",
        "      self.dense_att=tf.keras.layers.Dense(1)\n",
        "      self.softmax1=tf.keras.layers.Softmax(axis=1)\n",
        "  \n",
        "  \n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    '''\n",
        "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)\n",
        "    '''\n",
        "    if self.scoring_function == 'dot':\n",
        "        \n",
        "        # Implement Dot score function here\n",
        "        d1=tf.keras.layers.Dot(axes=(2,1))([encoder_output,tf.reshape(decoder_hidden_state,\n",
        "                                                  [decoder_hidden_state.shape[0],decoder_hidden_state.shape[1],1])])\n",
        "        d1_softmax=self.softmax1(d1)\n",
        "        \n",
        "        \n",
        "        #Find the context vector\n",
        "        d2=tf.keras.layers.Dot(axes=(1,2))([d1_softmax,\n",
        "                                                  tf.reshape(encoder_output,shape=[encoder_output.shape[0],encoder_output.shape[2],encoder_output.shape[1]])])\n",
        "        dt_dot=tf.reshape(d2,shape=[d2.shape[0],d2.shape[2]])\n",
        "        return dt_dot,d1_softmax\n",
        "\n",
        "    elif self.scoring_function == 'general':\n",
        "        # Implement General score function here\n",
        "        d1=self.dense1(decoder_hidden_state)\n",
        "        dt3=tf.reshape(d1,[d1.shape[0],d1.shape[1],1])\n",
        "        dt_general=tf.keras.layers.Dot(axes=(2,1))([encoder_output,dt3])\n",
        "        weights_general=self.softmax1(tf.cast(dt_general,dtype='float32'))\n",
        "        \n",
        "\n",
        "        # Find the context vector\n",
        "        d2=tf.keras.layers.Dot(axes=(1,2))([weights_general,tf.reshape(encoder_output,shape=[encoder_output.shape[0],encoder_output.shape[2],encoder_output.shape[1]])])\n",
        "        vector_general=tf.reshape(d2,shape=[d2.shape[0],d2.shape[2]])\n",
        "        return vector_general,weights_general\n",
        "\n",
        "                                                                             \n",
        "\n",
        "    elif self.scoring_function == 'concat':\n",
        "        \n",
        "        # Implementing concat function\n",
        "        dense_concat=self.dense_att(self.dense2(encoder_output)+tf.expand_dims(self.dense2(decoder_hidden_state),1))\n",
        "        softmax_concat=self.softmax1(tf.cast(dense_concat,dtype='float32'))#Finding the attention weight\n",
        "\n",
        "        #Finding the context vector\n",
        "\n",
        "        d2=tf.keras.layers.Dot(axes=(1,2))([softmax_concat,\n",
        "                                                  tf.reshape(encoder_output,shape=[encoder_output.shape[0],encoder_output.shape[2],encoder_output.shape[1]])])\n",
        "        vector_concat=tf.reshape(d2,shape=[d2.shape[0],d2.shape[2]])\n",
        "        return vector_concat,softmax_concat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQDlxI9LuqK"
      },
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51x50h_TLrl9",
        "outputId": "2e472142-ec90-4499-f0d8-6382062dce84"
      },
      "source": [
        "def grader_check_attention(scoring_fun):\n",
        "    \n",
        "    ''' \n",
        "        att_units: Used in matrix multiplications for scoring functions,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    \n",
        "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
        "    attention=Attention(scoring_fun,att_units)\n",
        "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
        "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))\n",
        "print(grader_check_attention('general'))\n",
        "print(grader_check_attention('concat'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "<font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8QqGj6MnO90"
      },
      "source": [
        "class OneStepDecoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      super().__init__()\n",
        "\n",
        "      self.tar_vocab_size=tar_vocab_size\n",
        "      self.embedding_dim=embedding_dim\n",
        "      self.input_length=input_length\n",
        "      self.dec_units=dec_units\n",
        "      self.score_fun=score_fun\n",
        "      self.att_units=att_units\n",
        "\n",
        "      self.embed_osd=Embedding(input_dim = self.tar_vocab_size, output_dim = self.embedding_dim,\n",
        "                                      input_length = self.input_length, name=\"embedding_layer_osd\")\n",
        "      self.lst_osd= LSTM(self.dec_units, return_sequences=True,return_state=True,name=\"osd_LSTM\")\n",
        "       \n",
        "      self.att_osd = Attention(self.score_fun,self.att_units)\n",
        "\n",
        "      self.dense_osd = Dense(self.tar_vocab_size)\n",
        "    \n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "\n",
        "    vec_osd,wgt=self.att_osd(state_h,encoder_output)\n",
        "    embed_target=self.embed_osd(input_to_decoder)\n",
        "    t=tf.expand_dims(vec_osd,1)\n",
        "    cnct=tf.concat([embed_target,t],axis=2)\n",
        "    output_osd,hid_osd,cell_osd=self.lst_osd(cnct)\n",
        "    output_osd=tf.reshape(output_osd,(-1,output_osd.shape[2]))\n",
        "    output_osd=self.dense_osd(output_osd)\n",
        "    return output_osd,hid_osd,cell_osd,wgt,vec_osd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_I8I4EIMAXq"
      },
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLEXhChnMC1k",
        "outputId": "32a48db4-6f79-4846-fbc5-946761426261"
      },
      "source": [
        "def grader_onestepdecoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        tar_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    tar_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    onestepdecoder=OneStepDecoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
        "    assert(output.shape==(batch_size,tar_vocab_size))\n",
        "    assert(state_h.shape==(batch_size,dec_units))\n",
        "    assert(state_c.shape==(batch_size,dec_units))\n",
        "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
        "    assert(context_vector.shape==(batch_size,dec_units))\n",
        "    return True\n",
        "    \n",
        "print(grader_onestepdecoder('dot'))\n",
        "print(grader_onestepdecoder('general'))\n",
        "print(grader_onestepdecoder('concat'))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "<font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syrQHkPtq0bs"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      super().__init__()\n",
        "      self.out_vocab_size=out_vocab_size\n",
        "      self.embedding_dim= embedding_dim\n",
        "      self.input_length =input_length\n",
        "      self.dec_units=dec_units\n",
        "      self.score_fun=score_fun\n",
        "      self.att_units=att_units\n",
        "      self.onestep_decoder = OneStepDecoder(self.out_vocab_size,self.embedding_dim,self.input_length,self.dec_units, self.score_fun,self.att_units)\n",
        "    \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "      var=tf.TensorArray(tf.float32,size=len(input_to_decoder[0]),name='tensor_deocoder')\n",
        "      for i in range(len(input_to_decoder[0])):\n",
        "        out1,hid_dec,cell_dec,wgt_dec,cnv_vec=self.onestep_decoder(input_to_decoder[:,i:i+1],encoder_output,decoder_hidden_state,decoder_cell_state)\n",
        "        var=var.write(i,out1)\n",
        "      var=tf.transpose(var.stack(),[1,0,2])\n",
        "      return var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxrL-P8bMJH6"
      },
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtbx6onFMJXb",
        "outputId": "2ec7beb9-9d26-4d49-8f80-f4c938fd2dca"
      },
      "source": [
        "def grader_decoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=11\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    \n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
        "    return True\n",
        "print(grader_decoder('dot'))\n",
        "print(grader_decoder('general'))\n",
        "print(grader_decoder('concat'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "<font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jpfikYfZkaj"
      },
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, input_len,output_len, score_ecm,att_units,batch_size):\n",
        "        \n",
        "        #Create encoder object\n",
        "        #Create decoder object\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "\n",
        "        super().__init__()\n",
        "        self.input_len=input_len\n",
        "        self.output_len=output_len\n",
        "        self.score_ecm=score_ecm\n",
        "        self.batch_size=batch_size\n",
        "        self.att_units=att_units\n",
        "        self.enc=Encoder(enc_vocab_size=vocab_size_ita+1,embedding_dim=50,input_length=input_len,enc_lstm_size=256)\n",
        "        self.dec=Decoder(out_vocab_size=vocab_size_eng+1,embedding_dim=100,dec_units=256,input_length=self.output_len,score_fun=self.score_ecm,att_units=self.att_units)\n",
        "        self.enc_state1,self.encoder_state2=self.enc.initialize_states(self.batch_size)\n",
        "    \n",
        "    \n",
        "    def call(self,input_ed):\n",
        "      enc_output,enc_hid,enc_cell=self.enc(input_ed[0],[self.enc_state1,self.encoder_state2])\n",
        "      decoder_output=self.dec(input_ed[1],enc_output,enc_hid,enc_cell)\n",
        "\n",
        "      return decoder_output\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "<font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfZET6OSxou8"
      },
      "source": [
        "loss1= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "def custom_lossfunction(targets,logits):\n",
        "\n",
        "  # Custom loss function that will not consider the loss for padded zeros.\n",
        "  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n",
        "  \n",
        "  target=tf.math.logical_not(tf.math.equal(targets,0))\n",
        "  loss2=loss1(targets,logits)\n",
        "  #masking loss for padding\n",
        "  \n",
        "  target=tf.cast(target,dtype=loss2.dtype)\n",
        "  loss2*=target\n",
        "\n",
        "  return tf.reduce_mean(loss2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QlbWAqNNlqe"
      },
      "source": [
        "<font color='blue'>**Training**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtZUQF2NuZE"
      },
      "source": [
        "Implement dot function here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnt1Xrluxz3i"
      },
      "source": [
        "class Data_en:\n",
        "    def __init__(self, data2, tknizer_ita, tknizer_eng, len_data):\n",
        "        self.in_encoder = data2['italian'].values\n",
        "        self.in_decoder = data2['english_inp'].values\n",
        "        self.out_decoder = data2['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.len_data = len_data\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.in_encoder[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.in_decoder[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.out_decoder[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.in_encoder)\n",
        "\n",
        "    \n",
        "class LoadData(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, data_lan, batch_size=1):\n",
        "        self.data_lan = data_lan\n",
        "        self.batch_size = batch_size\n",
        "        self.index_data = np.arange(len(self.data_lan.in_encoder))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        a = i * self.batch_size\n",
        "        b = (i + 1) * self.batch_size\n",
        "        data_val = []\n",
        "        for j in range(a, b):\n",
        "            data_val.append(self.data_lan[j])\n",
        "\n",
        "        batch_data = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data_val)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch_data[0],batch_data[1]],batch_data[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.index_data) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.index_data = np.random.permutation(self.index_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHejgRtSx6uB",
        "outputId": "73e7dd1a-a0e7-49df-c6f4-6b9512f77a37"
      },
      "source": [
        "train_enc1 = Data_en(train, tknizer_ita, tknizer_eng, 20)\n",
        "test_ecn1  = Data_en(validation, tknizer_ita, tknizer_eng, 20)\n",
        "\n",
        "train_load = LoadData(train_enc1, batch_size=1024)\n",
        "test_load = LoadData(test_ecn1, batch_size=1024)\n",
        "\n",
        "\n",
        "print(train_load[0][0][0].shape, train_load[0][0][1].shape, train_load[0][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1024, 20) (1024, 20) (1024, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvSu7Cgep761"
      },
      "source": [
        "tf.config.run_functions_eagerly(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bzlbIavhs0F",
        "outputId": "b8d7d64e-5f5c-4010-c1ef-dacf66ad371b"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ-InzoIyBfP"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "\n",
        "\n",
        "logdir2 = os.path.join(\"logs2\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback2= tf.keras.callbacks.TensorBoard(logdir1, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVWZraF9tzVK"
      },
      "source": [
        "model2 = encoder_decoder(input_len=20,output_len=20,score_ecm='dot',att_units=64,batch_size=1024)\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy')\n",
        "train_steps2=train.shape[0]//1024\n",
        "valid_steps2=validation.shape[0]//1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BqHntxXomk2",
        "outputId": "1fe42c45-b96c-4ea2-fd37-058e344d9a2d"
      },
      "source": [
        "model2.fit(train_load, steps_per_epoch=train_steps2, epochs=20, validation_data=train_load, validation_steps=valid_steps2,callbacks=[tensorboard_callback2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "274/274 [==============================] - 180s 634ms/step - loss: 2.2795 - val_loss: 2.2086\n",
            "Epoch 2/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 2.0567 - val_loss: 2.0998\n",
            "Epoch 3/20\n",
            "274/274 [==============================] - 168s 615ms/step - loss: 1.9903 - val_loss: 2.1099\n",
            "Epoch 4/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 1.9337 - val_loss: 2.1169\n",
            "Epoch 5/20\n",
            "274/274 [==============================] - 170s 620ms/step - loss: 1.9559 - val_loss: 2.1088\n",
            "Epoch 6/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 1.9167 - val_loss: 2.1478\n",
            "Epoch 7/20\n",
            "274/274 [==============================] - 169s 616ms/step - loss: 1.8669 - val_loss: 2.1071\n",
            "Epoch 8/20\n",
            "274/274 [==============================] - 169s 618ms/step - loss: 1.8785 - val_loss: 2.2818\n",
            "Epoch 9/20\n",
            "274/274 [==============================] - 169s 616ms/step - loss: 2.0188 - val_loss: 2.2763\n",
            "Epoch 10/20\n",
            "274/274 [==============================] - 169s 617ms/step - loss: 1.8769 - val_loss: 2.1157\n",
            "Epoch 11/20\n",
            "274/274 [==============================] - 169s 617ms/step - loss: 1.8726 - val_loss: 2.1139\n",
            "Epoch 12/20\n",
            "274/274 [==============================] - 162s 591ms/step - loss: 1.9173 - val_loss: 2.1381\n",
            "Epoch 13/20\n",
            "274/274 [==============================] - 169s 617ms/step - loss: 1.8898 - val_loss: 2.1971\n",
            "Epoch 14/20\n",
            "274/274 [==============================] - 169s 615ms/step - loss: 1.8776 - val_loss: 2.1445\n",
            "Epoch 15/20\n",
            "274/274 [==============================] - 160s 584ms/step - loss: 1.8333 - val_loss: 2.1426\n",
            "Epoch 16/20\n",
            "274/274 [==============================] - 161s 587ms/step - loss: 1.8258 - val_loss: 2.2093\n",
            "Epoch 17/20\n",
            "274/274 [==============================] - 159s 580ms/step - loss: 1.8800 - val_loss: 2.1719\n",
            "Epoch 18/20\n",
            "274/274 [==============================] - 169s 618ms/step - loss: 1.9721 - val_loss: 2.2018\n",
            "Epoch 19/20\n",
            "274/274 [==============================] - 160s 584ms/step - loss: 1.8712 - val_loss: 2.1326\n",
            "Epoch 20/20\n",
            "274/274 [==============================] - 161s 585ms/step - loss: 1.9660 - val_loss: 2.1298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22ba618b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLxgpthTyDiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165e98cc-330a-43f2-d76e-41c4cfd39d9f"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_decoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_3 (Encoder)          multiple                  1643268   \n",
            "_________________________________________________________________\n",
            "decoder_5 (Decoder)          multiple                  5296558   \n",
            "=================================================================\n",
            "Total params: 6,939,826\n",
            "Trainable params: 6,939,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1tYMGQYyDap"
      },
      "source": [
        "model2.save_weights('seq_dot_model2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DpC9zlzMcXp"
      },
      "source": [
        "## <font color='blue'>**Inference**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5NhESYyMW_t"
      },
      "source": [
        "<font color='blue'>**Plot attention weights**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ACiW1nryJB0"
      },
      "source": [
        "import matplotlib.ticker as ticker\n",
        "def plot_attention(attention,act,pred):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "\n",
        "  pred,_=predict(act,plot_t2='dot')\n",
        "  plot_att=attention[:len(pred.split(' ')),len(act.split(' '))]\n",
        "  fig,ax = plt.subplots(figsize=(8,6))\n",
        "  ax.matshow(attention,cmap='Blues')\n",
        "  ax.set_xticklabels([''] + act.split(' '), rotation=90)\n",
        "  ax.set_yticklabels([''] + pred.split(' '))\n",
        "  plt.show() \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1IhdBrgQYJr"
      },
      "source": [
        "<font color='blue'>**Predict the sentence translation**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR3rkRujyQoQ"
      },
      "source": [
        "def predict(input_sentence,plot_t2):\n",
        "\n",
        "  sentences=[]\n",
        "  in_enc_ita=tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  in_pad_seq_ita=pad_sequences(in_enc_ita,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
        "  state_enc1=model2.layers[0].initialize_states(in_pad_seq_ita.shape[0])\n",
        "  enc_ouput1,enc_state_h1,enc_state_c1=model2.layers[0](in_pad_seq_ita,state_enc1)\n",
        "  in_indexs=tknizer_eng.word_index['<start>']\n",
        "  in_indexs=tf.expand_dims([in_indexs],0)\n",
        "  att=np.zeros((20,20))\n",
        "  input_list=[]\n",
        "  for j in range(in_pad_seq_ita.shape[1]):\n",
        "    out_pred,dec_state_h1,dec_state_c1,w,cv=model2.layers[1].onestep_decoder(in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    dense_out1=model2.layers[1](in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    out_index=np.argmax(dense_out1)\n",
        "    wt=tf.reshape(w,(-1, ))\n",
        "    att[j]=wt.numpy()\n",
        "    in_indexs=np.reshape(out_index,(1,1))\n",
        "    input_list.append(tknizer_eng.index_word[out_index])\n",
        "    if tknizer_eng.index_word[out_index]=='<end>':\n",
        "      break\n",
        "  return ' '.join(input_list),att\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usOCV-6Pkk5X"
      },
      "source": [
        "**ATTETNTION PLOTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "pQeh7GV2j6W_",
        "outputId": "a3a080c4-0cd6-4107-dc7f-4a50317ae48b"
      },
      "source": [
        "pred,attention=predict('1 2 3 4','dot')\n",
        "plot_attention(attention,'1 2 3 4',pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxIVOOQPWMu"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iHiLdROM23l"
      },
      "source": [
        "# #Create an object of your custom model.\n",
        "# #Compile and train your model on dot scoring function.\n",
        "# # Visualize few sentences randomly in Test data\n",
        "# # Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# # https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "# #Sample example\n",
        "# import nltk.translate.bleu_score as bleu\n",
        "# reference = ['i am groot'.split(),] # the original\n",
        "# translation = 'it is ship'.split() # trasilated using model\n",
        "# print('BLEU score: {}'.format(bleu.sentence_bleu(reference, translation)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZr7et_Eycbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607a3d48-1726-441c-cb0d-7d5bc34e9711"
      },
      "source": [
        "ita=validation['italian'].values[:1000]\n",
        "eng=validation['english_out'].values[:1000]\n",
        "blue=[]\n",
        "for i in range(1000):\n",
        "  pred_bl,att_bl=predict(ita[i],'dot')\n",
        "  blue.append(bleu_score.sentence_bleu(eng[i],pred_bl))\n",
        "print(f'Bleu_score: {np.average(blue)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Bleu_score: 0.8246226835237551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvOcIxOHyhyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eba5a23-8d7d-4d2c-a093-707027f461c2"
      },
      "source": [
        "print(f'Bleu Score: {np.average(blue)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu Score: 0.8246226835237551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWg2ferDQvT3"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rh9_w79M5JO"
      },
      "source": [
        "#Compile and train your model on general scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xf850agyw4V"
      },
      "source": [
        "logdir3 = os.path.join(\"logs3\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback3= tf.keras.callbacks.TensorBoard(logdir1, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKqBjrlOLNRn"
      },
      "source": [
        "model3 = encoder_decoder(input_len=20,output_len=20,score_ecm='general',att_units=64,batch_size=1024)\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy')\n",
        "train_steps3=train.shape[0]//1024\n",
        "valid_steps3=validation.shape[0]//1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTrju7uJLUNx",
        "outputId": "83cbf78f-df76-41be-ace7-ef6926d55164"
      },
      "source": [
        "model3.fit(train_load, steps_per_epoch=train_steps3, epochs=20, validation_data=train_load, validation_steps=valid_steps3,callbacks=[tensorboard_callback3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "274/274 [==============================] - 170s 602ms/step - loss: 2.3031 - val_loss: 2.2873\n",
            "Epoch 2/20\n",
            "274/274 [==============================] - 161s 587ms/step - loss: 2.0556 - val_loss: 2.0834\n",
            "Epoch 3/20\n",
            "274/274 [==============================] - 169s 616ms/step - loss: 1.9527 - val_loss: 2.0697\n",
            "Epoch 4/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 1.9027 - val_loss: 2.0626\n",
            "Epoch 5/20\n",
            "274/274 [==============================] - 169s 618ms/step - loss: 1.8735 - val_loss: 2.0988\n",
            "Epoch 6/20\n",
            "274/274 [==============================] - 163s 593ms/step - loss: 1.9859 - val_loss: 2.0837\n",
            "Epoch 7/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 2.0781 - val_loss: 2.1448\n",
            "Epoch 8/20\n",
            "274/274 [==============================] - 169s 616ms/step - loss: 1.9704 - val_loss: 2.0715\n",
            "Epoch 9/20\n",
            "274/274 [==============================] - 169s 618ms/step - loss: 1.8394 - val_loss: 2.0547\n",
            "Epoch 10/20\n",
            "274/274 [==============================] - 172s 627ms/step - loss: 1.8451 - val_loss: 2.0558\n",
            "Epoch 11/20\n",
            "274/274 [==============================] - 162s 591ms/step - loss: 1.8470 - val_loss: 2.0613\n",
            "Epoch 12/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 1.8629 - val_loss: 2.0650\n",
            "Epoch 13/20\n",
            "274/274 [==============================] - 162s 593ms/step - loss: 1.7991 - val_loss: 2.0666\n",
            "Epoch 14/20\n",
            "274/274 [==============================] - 171s 624ms/step - loss: 1.8351 - val_loss: 2.0584\n",
            "Epoch 15/20\n",
            "274/274 [==============================] - 162s 590ms/step - loss: 1.7662 - val_loss: 2.0611\n",
            "Epoch 16/20\n",
            "274/274 [==============================] - 171s 623ms/step - loss: 1.7702 - val_loss: 2.0745\n",
            "Epoch 17/20\n",
            "274/274 [==============================] - 162s 590ms/step - loss: 1.8164 - val_loss: 2.1583\n",
            "Epoch 18/20\n",
            "274/274 [==============================] - 163s 593ms/step - loss: 1.7527 - val_loss: 2.0482\n",
            "Epoch 19/20\n",
            "274/274 [==============================] - 171s 623ms/step - loss: 1.7108 - val_loss: 2.1021\n",
            "Epoch 20/20\n",
            "274/274 [==============================] - 170s 620ms/step - loss: 1.7891 - val_loss: 2.0725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22ccba2c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgo0iw8uy1UJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ccbfd0e-93e9-483b-8643-519d5fa0f5db"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_decoder_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_4 (Encoder)          multiple                  1643268   \n",
            "_________________________________________________________________\n",
            "decoder_6 (Decoder)          multiple                  5296558   \n",
            "=================================================================\n",
            "Total params: 6,939,826\n",
            "Trainable params: 6,939,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ua_fmKWrrbw"
      },
      "source": [
        "%tensorboard --logdir logs3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GqDAETzy0x2"
      },
      "source": [
        "import matplotlib.ticker as ticker\n",
        "def plot_attention(attention,act,pred):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "\n",
        "  pred,_=predict(act,plot_t2='general')\n",
        "  plot_att=attention[:len(pred.split(' ')),len(act.split(' '))]\n",
        "  fig,ax = plt.subplots(figsize=(8,6))\n",
        "  ax.matshow(attention,cmap='Blues')\n",
        "  ax.set_xticklabels([''] + act.split(' '), rotation=90)\n",
        "  ax.set_yticklabels([''] + pred.split(' '))\n",
        "  plt.show() \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "-GW2mb4cYneK",
        "outputId": "c1651131-6d8c-4f60-8182-e10e872ac58c"
      },
      "source": [
        "pred,attention=predict('1 2 3 4','general')\n",
        "plot_attention(attention,'1 2 3 4',pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PxiQuDby41L"
      },
      "source": [
        "def predict(input_sentence,plot_t2):\n",
        "\n",
        "  sentences=[]\n",
        "  in_enc_ita=tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  in_pad_seq_ita=pad_sequences(in_enc_ita,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
        "  state_enc1=model3.layers[0].initialize_states(in_pad_seq_ita.shape[0])\n",
        "  enc_ouput1,enc_state_h1,enc_state_c1=model3.layers[0](in_pad_seq_ita,state_enc1)\n",
        "  in_indexs=tknizer_eng.word_index['<start>']\n",
        "  in_indexs=tf.expand_dims([in_indexs],0)\n",
        "  att=np.zeros((20,20))\n",
        "  input_list=[]\n",
        "  for j in range(in_pad_seq_ita.shape[1]):\n",
        "    out_pred,dec_state_h1,dec_state_c1,w,cv=model3.layers[1].onestep_decoder(in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    dense_out1=model3.layers[1](in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    out_index=np.argmax(dense_out1)\n",
        "    wt=tf.reshape(w,(-1, ))\n",
        "    att[j]=wt.numpy()\n",
        "    in_indexs=np.reshape(out_index,(1,1))\n",
        "    input_list.append(tknizer_eng.index_word[out_index])\n",
        "    if tknizer_eng.index_word[out_index]=='<end>':\n",
        "      break\n",
        "  return ' '.join(input_list),att\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJIATpUjkPji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbf360c-3512-4aae-c928-eb4e339d79a5"
      },
      "source": [
        "ita=validation['italian'].values[:1000]\n",
        "eng=validation['english_out'].values[:1000]\n",
        "blue=[]\n",
        "for i in range(1000):\n",
        "  pred_bl,att_bl=predict(ita[i],'general')\n",
        "  blue.append(bleu_score.sentence_bleu(eng[i],pred_bl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCROC9kSY6cr",
        "outputId": "6a9b6aad-1377-480b-9e8e-90d682ebc17f"
      },
      "source": [
        "print(f'Bleu_score: {np.average(blue)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu_score: 0.8705149732218294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB1jRUqZQ9AM"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kN9ZWViQNMB"
      },
      "source": [
        "#Compile and train your model on concat scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NflanuazD-J"
      },
      "source": [
        "logdir4 = os.path.join(\"logs4\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback4= tf.keras.callbacks.TensorBoard(logdir1, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6C2dI4lZSB4"
      },
      "source": [
        "model4 = encoder_decoder(input_len=20,output_len=20,score_ecm='concat',att_units=64,batch_size=1024)\n",
        "model4.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy')\n",
        "train_steps3=train.shape[0]//1024\n",
        "valid_steps3=validation.shape[0]//1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7G4n0NUZVrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0c3e9c-a1c5-4c65-9712-a4c7dd623f04"
      },
      "source": [
        "model4.fit(train_load, steps_per_epoch=train_steps3, epochs=20, validation_data=train_load, validation_steps=valid_steps3,callbacks=[tensorboard_callback4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "274/274 [==============================] - 187s 659ms/step - loss: 2.3358 - val_loss: 2.2126\n",
            "Epoch 2/20\n",
            "274/274 [==============================] - 184s 671ms/step - loss: 1.9897 - val_loss: 2.1768\n",
            "Epoch 3/20\n",
            "274/274 [==============================] - 183s 669ms/step - loss: 1.9982 - val_loss: 2.0986\n",
            "Epoch 4/20\n",
            "274/274 [==============================] - 183s 669ms/step - loss: 1.9786 - val_loss: 2.1295\n",
            "Epoch 5/20\n",
            "274/274 [==============================] - 184s 672ms/step - loss: 1.8858 - val_loss: 2.1411\n",
            "Epoch 6/20\n",
            "274/274 [==============================] - 177s 647ms/step - loss: 1.8964 - val_loss: 2.1293\n",
            "Epoch 7/20\n",
            "274/274 [==============================] - 176s 644ms/step - loss: 1.9157 - val_loss: 2.0868\n",
            "Epoch 8/20\n",
            "274/274 [==============================] - 176s 644ms/step - loss: 1.9690 - val_loss: 2.0937\n",
            "Epoch 9/20\n",
            "274/274 [==============================] - 182s 664ms/step - loss: 1.8564 - val_loss: 2.0578\n",
            "Epoch 10/20\n",
            "274/274 [==============================] - 184s 672ms/step - loss: 1.8450 - val_loss: 2.0726\n",
            "Epoch 11/20\n",
            "274/274 [==============================] - 183s 669ms/step - loss: 1.9960 - val_loss: 2.1153\n",
            "Epoch 12/20\n",
            "274/274 [==============================] - 182s 666ms/step - loss: 1.9400 - val_loss: 2.2613\n",
            "Epoch 13/20\n",
            "274/274 [==============================] - 183s 666ms/step - loss: 1.8545 - val_loss: 2.0846\n",
            "Epoch 14/20\n",
            "274/274 [==============================] - 183s 667ms/step - loss: 1.9415 - val_loss: 2.1064\n",
            "Epoch 15/20\n",
            "274/274 [==============================] - 183s 666ms/step - loss: 1.8513 - val_loss: 2.0828\n",
            "Epoch 16/20\n",
            "274/274 [==============================] - 176s 642ms/step - loss: 1.8114 - val_loss: 2.0665\n",
            "Epoch 17/20\n",
            "274/274 [==============================] - 183s 668ms/step - loss: 1.7609 - val_loss: 2.0643\n",
            "Epoch 18/20\n",
            "274/274 [==============================] - 176s 643ms/step - loss: 1.8445 - val_loss: 2.1551\n",
            "Epoch 19/20\n",
            "274/274 [==============================] - 181s 661ms/step - loss: 1.9178 - val_loss: 2.1682\n",
            "Epoch 20/20\n",
            "274/274 [==============================] - 183s 667ms/step - loss: 1.8762 - val_loss: 2.1254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f225cbfa790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRbRL2K8zGxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eeb0bc4-3132-4f45-9989-59451c0ffb0d"
      },
      "source": [
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_decoder_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_5 (Encoder)          multiple                  1643268   \n",
            "_________________________________________________________________\n",
            "decoder_7 (Decoder)          multiple                  5329519   \n",
            "=================================================================\n",
            "Total params: 6,972,787\n",
            "Trainable params: 6,972,787\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogp300Z0zLW5"
      },
      "source": [
        "model4.save_weights('concat_model4.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l3J_rzbrw75"
      },
      "source": [
        "!kill 1690"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "afpdHBnUrnWN",
        "outputId": "2ca9f3dd-8f47-4a48-ef09-fb039372ea05"
      },
      "source": [
        "%tensorboard --logdir logs4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LRVqM68Z9Fz"
      },
      "source": [
        "def predict(input_sentence,plot_t2):\n",
        "\n",
        "  sentences=[]\n",
        "  in_enc_ita=tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  in_pad_seq_ita=pad_sequences(in_enc_ita,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
        "  state_enc1=model4.layers[0].initialize_states(in_pad_seq_ita.shape[0])\n",
        "  enc_ouput1,enc_state_h1,enc_state_c1=model4.layers[0](in_pad_seq_ita,state_enc1)\n",
        "  in_indexs=tknizer_eng.word_index['<start>']\n",
        "  in_indexs=tf.expand_dims([in_indexs],0)\n",
        "  att=np.zeros((20,20))\n",
        "  input_list=[]\n",
        "  for j in range(in_pad_seq_ita.shape[1]):\n",
        "    out_pred,dec_state_h1,dec_state_c1,w,cv=model4.layers[1].onestep_decoder(in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    dense_out1=model4.layers[1](in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    out_index=np.argmax(dense_out1)\n",
        "    wt=tf.reshape(w,(-1, ))\n",
        "    att[j]=wt.numpy()\n",
        "    in_indexs=np.reshape(out_index,(1,1))\n",
        "    input_list.append(tknizer_eng.index_word[out_index])\n",
        "    if tknizer_eng.index_word[out_index]=='<end>':\n",
        "      break\n",
        "  return ' '.join(input_list),att\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8-4XDE5zKrh"
      },
      "source": [
        "import matplotlib.ticker as ticker\n",
        "def plot_attention(attention,act,pred):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "\n",
        "  pred,_=predict(act,plot_t2='concat')\n",
        "  plot_att=attention[:len(pred.split(' ')),len(act.split(' '))]\n",
        "  fig,ax = plt.subplots(figsize=(8,6))\n",
        "  ax.matshow(attention,cmap='Blues')\n",
        "  ax.set_xticklabels([''] + act.split(' '), rotation=90)\n",
        "  ax.set_yticklabels([''] + pred.split(' '))\n",
        "  plt.show() \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLQlEDEGaI_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "21c843a9-f7a5-49b8-e3b2-c68f1a6cf61d"
      },
      "source": [
        "pred,attention=predict('1 2 3 4','concat')\n",
        "plot_attention(attention,'1 2 3 4',pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbmmEMtazNyT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da81fa6-32ca-4580-d0c2-726e8030ae78"
      },
      "source": [
        "ita=validation['italian'].values[:1000]\n",
        "eng=validation['english_out'].values[:1000]\n",
        "blue=[]\n",
        "for i in range(1000):\n",
        "  pred_bl,att_bl=predict(ita[i],'concat')\n",
        "  blue.append(bleu_score.sentence_bleu(eng[i],pred_bl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3JaPGSFZvZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0ef35e-b0d2-4355-ae84-efc2274200ae"
      },
      "source": [
        "print(f'Bleu_score: {np.average(blue)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu_score: 0.5097968335141377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff1lV0ITM6_p"
      },
      "source": [
        "# Write your observations on each of the scoring function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLo30Q7Istma"
      },
      "source": [
        "**OBSERVATIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAybyE8LtS7R",
        "outputId": "e0ac0566-a4f5-46fb-ea69-12132db46b76"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "x = PrettyTable()\n",
        "x.field_names = [\"No\",\"Scoring Function\", \"Bleu Score\"]\n",
        "\n",
        "x.add_row([\"1\",\"Dot\",0.8246 ])\n",
        "x.add_row([\"2\",\"General\", 0.8705])\n",
        "x.add_row([\"3\",\"Concat \", 0.509])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+------------------+------------+\n",
            "| No | Scoring Function | Bleu Score |\n",
            "+----+------------------+------------+\n",
            "| 1  |       Dot        |   0.8246   |\n",
            "| 2  |     General      |   0.8705   |\n",
            "| 3  |     Concat       |   0.509    |\n",
            "+----+------------------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}